{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "028100a5-7fdd-4520-a5eb-4ea8be54e206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VEHICLE CRASH SEVERITY - COMPLETE PREPROCESSING PIPELINE\n",
      "======================================================================\n",
      "\n",
      "[1/8] Loading dataset...\n",
      "File size: 2.85 GB\n",
      "Large file - sampling 500K rows...\n",
      "Loaded: 500,000 rows, 46 columns\n",
      "\n",
      "[2/8] Creating binary severity target...\n",
      "Target distribution:\n",
      "Severity_Binary\n",
      "0    312547\n",
      "1    187453\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[3/8] Selecting relevant features...\n",
      "Selected 15 features from 15 requested\n",
      "New shape: (500000, 15)\n",
      "\n",
      "[4/8] Handling missing values...\n",
      "Missing values before: 578,766\n",
      "Rows after dropping missing target: 500,000\n",
      "Missing values after imputation: 0\n",
      "\n",
      "[5/8] Encoding categorical variables...\n",
      "Weather encoded. Shape now: (500000, 24)\n",
      "\n",
      "[6/8] Engineering time features...\n",
      "Time features created: Hour, DayOfWeek, Month, IsWeekend, Hour_Category\n",
      "Rows after dropping all NaN: 500,000\n",
      "\n",
      "[7/8] Balancing classes...\n",
      "Before balancing:\n",
      "  Low (0): 312,547\n",
      "  High (1): 187,453\n",
      "\n",
      "After balancing:\n",
      "Severity_Binary\n",
      "0    187453\n",
      "1    187453\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[8/8] Final validation...\n",
      "\n",
      "======================================================================\n",
      "FINAL PREPROCESSED DATASET\n",
      "======================================================================\n",
      "Shape: (374906, 28)\n",
      "Rows: 374,906\n",
      "Features: 28\n",
      "Missing values: 0\n",
      "\n",
      "Target distribution:\n",
      "Severity_Binary\n",
      "0    187453\n",
      "1    187453\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data types:\n",
      "bool       10\n",
      "int64       9\n",
      "float64     6\n",
      "int32       3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Features (27 total):\n",
      "   1. Temperature(F)\n",
      "   2. Humidity(%)\n",
      "   3. Pressure(in)\n",
      "   4. Visibility(mi)\n",
      "   5. Wind_Speed(mph)\n",
      "   6. Precipitation(in)\n",
      "   7. Junction\n",
      "   8. Traffic_Signal\n",
      "   9. Stop\n",
      "  10. Crossing\n",
      "  11. Sunrise_Sunset\n",
      "  12. Civil_Twilight\n",
      "  13. Weather_Fair\n",
      "  14. Weather_Haze\n",
      "  15. Weather_Light Rain\n",
      "  16. Weather_Light Snow\n",
      "  17. Weather_Mostly Cloudy\n",
      "  18. Weather_Other\n",
      "  19. Weather_Overcast\n",
      "  20. Weather_Partly Cloudy\n",
      "  21. Weather_Rain\n",
      "  22. Weather_Scattered Clouds\n",
      "  23. Hour\n",
      "  24. DayOfWeek\n",
      "  25. Month\n",
      "  26. IsWeekend\n",
      "  27. Hour_Category\n",
      "\n",
      "======================================================================\n",
      "✅ PREPROCESSING COMPLETE!\n",
      "======================================================================\n",
      "Saved: ../data/processed/clean_crash_data.csv\n",
      "Ready for modeling!\n"
     ]
    }
   ],
   "source": [
    "# COMPLETE PREPROCESSING IN ONE CELL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"VEHICLE CRASH SEVERITY - COMPLETE PREPROCESSING PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD DATA\n",
    "# ============================================================================\n",
    "print(\"\\n[1/8] Loading dataset...\")\n",
    "file_path = '../data/raw/US_Accidents_March23.csv'  # Update if different\n",
    "\n",
    "# Sample if file is too large\n",
    "import os\n",
    "file_size_gb = os.path.getsize(file_path) / (1024**3)\n",
    "print(f\"File size: {file_size_gb:.2f} GB\")\n",
    "\n",
    "if file_size_gb > 2:\n",
    "    print(\"Large file - sampling 500K rows...\")\n",
    "    df = pd.read_csv(file_path, nrows=500000)\n",
    "else:\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Loaded: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: CREATE BINARY TARGET\n",
    "# ============================================================================\n",
    "print(\"\\n[2/8] Creating binary severity target...\")\n",
    "df['Severity_Binary'] = df['Severity'].apply(lambda x: 0 if x <= 2 else 1)\n",
    "print(f\"Target distribution:\\n{df['Severity_Binary'].value_counts()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: SELECT RELEVANT FEATURES\n",
    "# ============================================================================\n",
    "print(\"\\n[3/8] Selecting relevant features...\")\n",
    "\n",
    "features_to_keep = [\n",
    "    'Severity_Binary',  # Target\n",
    "    'Temperature(F)', 'Humidity(%)', 'Pressure(in)',\n",
    "    'Visibility(mi)', 'Wind_Speed(mph)', 'Precipitation(in)',\n",
    "    'Weather_Condition', 'Start_Time',\n",
    "    'Junction', 'Traffic_Signal', 'Stop', 'Crossing',\n",
    "    'Sunrise_Sunset', 'Civil_Twilight'\n",
    "]\n",
    "\n",
    "# Keep only features that exist\n",
    "available = [f for f in features_to_keep if f in df.columns]\n",
    "print(f\"Selected {len(available)} features from {len(features_to_keep)} requested\")\n",
    "\n",
    "df = df[available].copy()\n",
    "print(f\"New shape: {df.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: HANDLE MISSING VALUES\n",
    "# ============================================================================\n",
    "print(\"\\n[4/8] Handling missing values...\")\n",
    "print(f\"Missing values before: {df.isnull().sum().sum():,}\")\n",
    "\n",
    "# Drop rows where target is missing\n",
    "df = df.dropna(subset=['Severity_Binary'])\n",
    "print(f\"Rows after dropping missing target: {len(df):,}\")\n",
    "\n",
    "# Fill numeric columns with median\n",
    "numeric_cols = ['Temperature(F)', 'Humidity(%)', 'Pressure(in)',\n",
    "                'Visibility(mi)', 'Wind_Speed(mph)', 'Precipitation(in)']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns and df[col].isnull().sum() > 0:\n",
    "        median_val = df[col].median()\n",
    "        df[col].fillna(median_val, inplace=True)\n",
    "        \n",
    "# Fill categorical with mode\n",
    "cat_cols = ['Weather_Condition', 'Sunrise_Sunset', 'Civil_Twilight',\n",
    "            'Junction', 'Traffic_Signal', 'Stop', 'Crossing']\n",
    "\n",
    "for col in cat_cols:\n",
    "    if col in df.columns and df[col].isnull().sum() > 0:\n",
    "        mode_val = df[col].mode()[0] if len(df[col].mode()) > 0 else 'Unknown'\n",
    "        df[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "print(f\"Missing values after imputation: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: ENCODE CATEGORICAL VARIABLES\n",
    "# ============================================================================\n",
    "print(\"\\n[5/8] Encoding categorical variables...\")\n",
    "\n",
    "# Binary encoding\n",
    "binary_maps = {\n",
    "    'Sunrise_Sunset': {'Day': 1, 'Night': 0},\n",
    "    'Civil_Twilight': {'Day': 1, 'Night': 0}\n",
    "}\n",
    "\n",
    "for col, mapping in binary_maps.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].map(mapping).fillna(0).astype(int)\n",
    "\n",
    "# Boolean columns\n",
    "bool_cols = ['Junction', 'Traffic_Signal', 'Stop', 'Crossing']\n",
    "for col in bool_cols:\n",
    "    if col in df.columns:\n",
    "        # Convert True/False to 1/0\n",
    "        df[col] = df[col].map({True: 1, False: 0, 'True': 1, 'False': 0}).fillna(0).astype(int)\n",
    "\n",
    "# Weather - keep top 10, make rest \"Other\", then one-hot encode\n",
    "if 'Weather_Condition' in df.columns:\n",
    "    top_weather = df['Weather_Condition'].value_counts().head(10).index.tolist()\n",
    "    df['Weather_Condition'] = df['Weather_Condition'].apply(\n",
    "        lambda x: x if x in top_weather else 'Other'\n",
    "    )\n",
    "    df = pd.get_dummies(df, columns=['Weather_Condition'], prefix='Weather', drop_first=True)\n",
    "    print(f\"Weather encoded. Shape now: {df.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: ENGINEER TIME FEATURES\n",
    "# ============================================================================\n",
    "print(\"\\n[6/8] Engineering time features...\")\n",
    "\n",
    "if 'Start_Time' in df.columns:\n",
    "    df['Start_Time'] = pd.to_datetime(df['Start_Time'], errors='coerce')\n",
    "    df['Hour'] = df['Start_Time'].dt.hour\n",
    "    df['DayOfWeek'] = df['Start_Time'].dt.dayofweek\n",
    "    df['Month'] = df['Start_Time'].dt.month\n",
    "    df['IsWeekend'] = (df['DayOfWeek'] >= 5).astype(int)\n",
    "    \n",
    "    # Hour categories\n",
    "    def hour_cat(h):\n",
    "        if pd.isna(h): return 0\n",
    "        if 6 <= h < 12: return 1\n",
    "        elif 12 <= h < 18: return 2\n",
    "        elif 18 <= h < 22: return 3\n",
    "        else: return 4\n",
    "    \n",
    "    df['Hour_Category'] = df['Hour'].apply(hour_cat)\n",
    "    df = df.drop('Start_Time', axis=1)\n",
    "    print(\"Time features created: Hour, DayOfWeek, Month, IsWeekend, Hour_Category\")\n",
    "\n",
    "# Drop any remaining NaN rows\n",
    "df = df.dropna()\n",
    "print(f\"Rows after dropping all NaN: {len(df):,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: BALANCE CLASSES\n",
    "# ============================================================================\n",
    "print(\"\\n[7/8] Balancing classes...\")\n",
    "\n",
    "df_0 = df[df['Severity_Binary'] == 0]\n",
    "df_1 = df[df['Severity_Binary'] == 1]\n",
    "\n",
    "print(f\"Before balancing:\")\n",
    "print(f\"  Low (0): {len(df_0):,}\")\n",
    "print(f\"  High (1): {len(df_1):,}\")\n",
    "\n",
    "# Only balance if we have enough data\n",
    "if len(df) > 10000:\n",
    "    if len(df_0) > len(df_1):\n",
    "        df_0_down = resample(df_0, n_samples=len(df_1), random_state=42, replace=False)\n",
    "        df_balanced = pd.concat([df_0_down, df_1])\n",
    "    else:\n",
    "        df_1_down = resample(df_1, n_samples=len(df_0), random_state=42, replace=False)\n",
    "        df_balanced = pd.concat([df_0, df_1_down])\n",
    "    \n",
    "    df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    print(f\"\\nAfter balancing:\")\n",
    "    print(df_balanced['Severity_Binary'].value_counts())\n",
    "else:\n",
    "    print(\"⚠️ Not enough data to balance\")\n",
    "    df_balanced = df\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: FINAL VALIDATION & SAVE\n",
    "# ============================================================================\n",
    "print(\"\\n[8/8] Final validation...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL PREPROCESSED DATASET\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Shape: {df_balanced.shape}\")\n",
    "print(f\"Rows: {df_balanced.shape[0]:,}\")\n",
    "print(f\"Features: {df_balanced.shape[1]}\")\n",
    "print(f\"Missing values: {df_balanced.isnull().sum().sum()}\")\n",
    "\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df_balanced['Severity_Binary'].value_counts())\n",
    "\n",
    "# Verify all numeric\n",
    "print(f\"\\nData types:\")\n",
    "print(df_balanced.dtypes.value_counts())\n",
    "\n",
    "# Show features\n",
    "features = [col for col in df_balanced.columns if col != 'Severity_Binary']\n",
    "print(f\"\\nFeatures ({len(features)} total):\")\n",
    "for i, col in enumerate(features, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# Save\n",
    "output_file = '../data/processed/clean_crash_data.csv'\n",
    "df_balanced.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ PREPROCESSING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Saved: {output_file}\")\n",
    "print(\"Ready for modeling!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3606f686-7c8a-46e5-b088-49841e097758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
